eplines 极线

epipole 极点

Fundamental Matrix 基本矩阵

Epipolar Matrix对极矩阵

# 线性几何

## 目标

在本章中，

- 我们将了解基础的多视图几何
- 我们将看到什么是极点，极线，线性约束等等

## 基本概念

当我们使用针孔摄像机拍照的时候，我们将失去一个重要的信息，即图像的深度。或者是每一个点由于3D到2D转换导致的到摄像机远近距离问题。所以这有着一个严重的问题就是我们能否使用这些摄像机找到深度信息。这个问题的答案便是使用不止一个摄像机。我们的眼睛也以相似的方式工作，我们使用两个摄像机(两只眼睛)，这种方案分支被称作立体视觉。所以让我们看看OpenCV在这个领域提供了什么信息。

(《学习OpenCV》(Gary Bradsky著)有着关于这个领域很多的知识)

在我们投入到图像深度前，我们首先先要了解一些关于多视图几何的基本概念。在这一部分，我们将讨论线性几何。请看下面这张图片，它展示了一个两个摄像头拍摄相同场景的基本配置。

![epipolar](img/epipolar.jpg)

<center>epipolar image</center>

如果我们只使用左边的摄像机，我们将不能找到3D点在图像中对应的$$x$$坐标因为在$$OX$$直线上的每一个点都会投影到图像平面中的同一个点。但是我们也会考虑右侧的图像。现在，$$OX$$直线上的不同的点会投影到右平面上不同的点($$x'$$)了。所以通过这两个图像，我们便可以三角测量出正确的3D点。这便是整个的思路。

所有在$$OX$$上不同的点在右平面上形成了一条直线(直线$$l'$$)。我们将其称为点$$x$$对应的**极线**。这意味着在右侧图像寻找点$$x$$仅需要搜寻极线上的点。这个点可能在这条线的任意位置(试想一下，为了在图像中寻找到匹配点，你不需要在整张图像中寻找，而是仅在一条极线上寻找。这会大大提升运算效率和准确性)。这种方法被称作**线性约束**。类似地，所有点将在另一图像中具有其对应的极线。平面$$XOO'$$被称作**极平面**。

$$O$$和$$O'$$是相机投影中心。通过上面的方法，我们可以看到右侧摄像机的$$O'$$在左侧图像上的投影点，$$e$$。这个点被称作**极点**。



所有极线都会过极点。





![essential_matrix.jpg](img/essential_matrix.jpg)

<center>essential matrix image</center>





## 代码

首先，我们需要在两个图像之间找到尽可能多的匹配，以找到基本矩阵。为此，我们将SIFT描述符与基于FLANN的匹配器和比率测试结合使用。

```python
import numpy as np
import cv2 as cv
from matplotlib import pyplot as plt

img1 = cv.imread('myleft.jpg',0)  #queryimage # left image
img2 = cv.imread('myright.jpg',0) #trainimage # right image

sift = cv.SIFT()

# find the keypoints and descriptors with SIFT
kp1, des1 = sift.detectAndCompute(img1,None)
kp2, des2 = sift.detectAndCompute(img2,None)

# FLANN parameters
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks=50)

flann = cv.FlannBasedMatcher(index_params,search_params)
matches = flann.knnMatch(des1,des2,k=2)

good = []
pts1 = []
pts2 = []

# ratio test as per Lowe's paper
for i,(m,n) in enumerate(matches):
    if m.distance < 0.8*n.distance:
        good.append(m)
        pts2.append(kp2[m.trainIdx].pt)
        pts1.append(kp1[m.queryIdx].pt)
```

现在我们有两张图片的最佳匹配列表。让我们找到基本矩阵。

```python
pts1 = np.int32(pts1)
pts2 = np.int32(pts2)
F, mask = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)

# We select only inlier points
pts1 = pts1[mask.ravel()==1]
pts2 = pts2[mask.ravel()==1]
```







下面就是我们得到的结果：

![epiresult.jpg](img/epiresult.jpg)

<center>epiresult image</center>





为了获得更好的效果，应使用具有良好分辨率且包含许多非平面点的图像。

## 其他资源

## 练习

